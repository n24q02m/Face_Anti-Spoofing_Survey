{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import json\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(\n",
    "    image_size=224, \n",
    "    margin=0,\n",
    "    min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7],\n",
    "    factor=0.709,\n",
    "    device=device,\n",
    "    keep_all=False\n",
    ")\n",
    "\n",
    "# Download dataset from Kaggle\n",
    "print(\"Downloading dataset...\")\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files('hlly34/liveness-detection-zalo-2022', path='/kaggle/working', unzip=True)\n",
    "\n",
    "# Create new dataset structure\n",
    "dataset_root = Path('/kaggle/working/Zalo_AIC_dataset') \n",
    "for folder in ['live', 'spoof']:\n",
    "    (dataset_root / folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read labels and move videos to appropriate folders\n",
    "print(\"\\nMoving videos to live/spoof folders...\")\n",
    "label_file = Path('/kaggle/working/train/train/label.csv')\n",
    "labels_df = pd.read_csv(label_file)\n",
    "\n",
    "for _, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
    "    src = Path('/kaggle/working/train/train/videos') / row['fname']\n",
    "    if row['liveness_score'] == 1:\n",
    "        dst = dataset_root / 'live' / row['fname']\n",
    "    else:\n",
    "        dst = dataset_root / 'spoof' / row['fname']\n",
    "    shutil.move(str(src), str(dst))\n",
    "\n",
    "# Remove original dataset\n",
    "print(\"\\nRemoving original dataset...\")\n",
    "shutil.rmtree('/kaggle/working/train')\n",
    "\n",
    "# Function to extract frames from video\n",
    "def extract_frames(video_path, save_dir, start_idx):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return start_idx\n",
    "        \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    idx = start_idx\n",
    "    for sec in range(int(duration)):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, sec * fps)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            save_path = save_dir / f\"{idx:06d}.jpg\"\n",
    "            cv2.imwrite(str(save_path), frame)\n",
    "            idx += 1\n",
    "            \n",
    "    cap.release()\n",
    "    return idx\n",
    "\n",
    "# Extract frames from all videos\n",
    "print(\"\\nExtracting frames from videos...\")\n",
    "next_idx = 1\n",
    "for folder in ['live', 'spoof']:\n",
    "    folder_path = dataset_root / folder\n",
    "    videos = list(folder_path.glob('*.mp4'))\n",
    "    \n",
    "    for video in tqdm(videos, desc=f\"Processing {folder} videos\"):\n",
    "        next_idx = extract_frames(video, folder_path, next_idx)\n",
    "        video.unlink()  # Delete video after extracting frames\n",
    "\n",
    "# Function to detect face and save bounding box\n",
    "def detect_face(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "            \n",
    "        real_h, real_w = img.shape[:2]\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        boxes, probs = mtcnn.detect(img_rgb)\n",
    "        \n",
    "        if boxes is None or len(boxes) == 0:\n",
    "            return False\n",
    "            \n",
    "        box = boxes[0]\n",
    "        prob = probs[0]\n",
    "        \n",
    "        x1, y1, x2, y2 = box\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        \n",
    "        x = int(x1 * 224 / real_w)\n",
    "        y = int(y1 * 224 / real_h)\n",
    "        w = int(w * 224 / real_w)\n",
    "        h = int(h * 224 / real_h)\n",
    "        \n",
    "        bb_path = img_path.parent / f\"{img_path.stem}_BB.txt\"\n",
    "        with open(bb_path, 'w') as f:\n",
    "            f.write(f\"{x} {y} {w} {h} {prob:.7f}\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Detect faces in all images\n",
    "print(\"\\nDetecting faces...\")\n",
    "for folder in ['live', 'spoof']:\n",
    "    folder_path = dataset_root / folder\n",
    "    images = list(folder_path.glob('*.jpg'))\n",
    "    \n",
    "    for img_path in tqdm(images, desc=f\"Processing {folder} images\"):\n",
    "        if not detect_face(img_path):\n",
    "            img_path.unlink()\n",
    "\n",
    "# Function to rename files with new indices\n",
    "def rename_files(folder_path, start_idx=1):\n",
    "    files = sorted(f for f in folder_path.iterdir() if not f.name.endswith('_BB.txt'))\n",
    "    \n",
    "    # First rename to 7 digits\n",
    "    print(f\"Converting {folder_path.name} to 7 digits...\")\n",
    "    for idx, file in enumerate(tqdm(files)):\n",
    "        ext = file.suffix\n",
    "        # Rename image\n",
    "        new_name = f\"{(idx+1):07d}{ext}\"\n",
    "        new_path = file.parent / new_name\n",
    "        file.rename(new_path)\n",
    "        \n",
    "        # Rename BB file if exists\n",
    "        bb_file = file.parent / f\"{file.stem}_BB.txt\"\n",
    "        if bb_file.exists():\n",
    "            new_bb_name = f\"{(idx+1):07d}_BB.txt\"\n",
    "            new_bb_path = file.parent / new_bb_name\n",
    "            bb_file.rename(new_bb_path)\n",
    "    \n",
    "    # Then rename back to 6 digits\n",
    "    files = sorted(f for f in folder_path.iterdir() if not f.name.endswith('_BB.txt'))\n",
    "    print(f\"Renaming {folder_path.name} to 6 digits...\")\n",
    "    for idx, file in enumerate(tqdm(files)):\n",
    "        ext = file.suffix\n",
    "        # Rename image\n",
    "        new_name = f\"{(start_idx+idx):06d}{ext}\"\n",
    "        new_path = file.parent / new_name\n",
    "        file.rename(new_path)\n",
    "        \n",
    "        # Rename BB file if exists\n",
    "        bb_file = file.parent / f\"{file.stem}_BB.txt\"\n",
    "        if bb_file.exists():\n",
    "            new_bb_name = f\"{(start_idx+idx):06d}_BB.txt\"\n",
    "            new_bb_path = file.parent / new_bb_name\n",
    "            bb_file.rename(new_bb_path)\n",
    "\n",
    "# Rename all files\n",
    "print(\"\\nRenaming files...\")\n",
    "live_path = dataset_root / 'live'\n",
    "spoof_path = dataset_root / 'spoof'\n",
    "\n",
    "rename_files(live_path)  # Start live files from 000001\n",
    "live_count = len(list(f for f in live_path.iterdir() if not f.name.endswith('_BB.txt')))\n",
    "rename_files(spoof_path, start_idx=live_count+1)  # Continue numbering for spoof files\n",
    "\n",
    "# Create and upload new dataset\n",
    "print(\"\\nCreating Kaggle dataset...\")\n",
    "metadata = {\n",
    "    'title': 'Zalo-AIC - Face Anti-Spoofing Dataset',\n",
    "    'id': 'zalo-aic-face-anti-spoofing-dataset', \n",
    "    'licenses': [{'name': 'CC0-1.0'}]\n",
    "}\n",
    "\n",
    "metadata_path = dataset_root / 'dataset-metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Uploading dataset to Kaggle...\")\n",
    "api.dataset_create_new(\n",
    "    folder=str(dataset_root),\n",
    "    dir_mode='zip',\n",
    "    quiet=False\n",
    ")\n",
    "\n",
    "print(\"\\nAll done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
