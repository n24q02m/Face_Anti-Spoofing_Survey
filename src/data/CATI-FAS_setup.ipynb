{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from google.colab import userdata, drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/root/.config/kaggle\", exist_ok=True)\n",
    "kaggle_token = {\n",
    "    \"username\": userdata.get('username'),\n",
    "    \"key\": userdata.get('kaggle-api-key')\n",
    "}\n",
    "\n",
    "with open(\"/root/.config/kaggle/kaggle.json\", \"w\") as f:\n",
    "    json.dump(kaggle_token, f)\n",
    "!chmod 600 /root/.config/kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# utput data directory\n",
    "OUTPUT_DIR = \"/content/CATI-FAS_dataset\"\n",
    "\n",
    "# Create output directories\n",
    "for subdir in [\"live\", \"spoof\"]:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, subdir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset folders from Google Drive\n",
    "def download_folders():\n",
    "    \"\"\"Download dataset folders from Google Drive\"\"\"\n",
    "    gdrive_path = \"/content/drive/MyDrive/CATI-FAS_dataset\"\n",
    "\n",
    "    if not os.path.exists(gdrive_path):\n",
    "        print(f\"Google Drive path {gdrive_path} not found\")\n",
    "        return False\n",
    "\n",
    "    # Copy dataset from Google Drive to local directory\n",
    "    shutil.copytree(gdrive_path, \"temp_download\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and move files\n",
    "def extract_and_move_files():\n",
    "    \"\"\"Extract zip files and move contents to appropriate folders\"\"\"\n",
    "\n",
    "    # Process both live and spoof folders\n",
    "    for data_type in [\"live\", \"spoof\"]:\n",
    "        source_dir = os.path.join(\"temp_download\", data_type)\n",
    "        target_dir = os.path.join(OUTPUT_DIR, data_type)\n",
    "\n",
    "        if not os.path.exists(source_dir):\n",
    "            print(f\"Source directory {source_dir} not found\")\n",
    "            continue\n",
    "\n",
    "        # Find all zip files\n",
    "        zip_files = list(Path(source_dir).rglob(\"*.zip\"))\n",
    "\n",
    "        print(f\"\\nProcessing {data_type} files...\")\n",
    "        for zip_file in tqdm(zip_files):\n",
    "            # Extract to temporary folder\n",
    "            temp_extract = os.path.join(\"temp_extract\", zip_file.stem)\n",
    "            os.makedirs(temp_extract, exist_ok=True)\n",
    "\n",
    "            with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(temp_extract)\n",
    "\n",
    "            # Move image files to target directory\n",
    "            for img_file in Path(temp_extract).rglob(\"*.*\"):\n",
    "                if img_file.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                    # Only move if file doesn't exist in target\n",
    "                    target_path = os.path.join(target_dir, img_file.name)\n",
    "                    if not os.path.exists(target_path):\n",
    "                        shutil.move(str(img_file), target_dir)\n",
    "\n",
    "            # Clean up temporary extraction folder\n",
    "            shutil.rmtree(temp_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Kaggle\n",
    "def upload_to_kaggle():\n",
    "    \"\"\"Upload dataset to Kaggle\"\"\"\n",
    "\n",
    "    # Create dataset metadata\n",
    "    metadata = {\n",
    "        \"title\": \"CATI-FAS - Face Anti-Spoofing Dataset\",\n",
    "        \"id\": f\"{userdata.get('username')}/cati-fas-face-anti-spoofing-dataset\",\n",
    "        \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "    }\n",
    "\n",
    "    metadata_path = os.path.join(OUTPUT_DIR, \"dataset-metadata.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    print(\"\\nUploading to Kaggle...\")\n",
    "    try:\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=OUTPUT_DIR, dir_mode=\"zip\", quiet=False)\n",
    "        print(\"Dataset created successfully on Kaggle!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to Kaggle: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution flow\n",
    "if download_folders():\n",
    "    extract_and_move_files()\n",
    "\n",
    "    # Clean up temporary download folder\n",
    "    shutil.rmtree(\"temp_download\")\n",
    "\n",
    "    # Upload to Kaggle\n",
    "    upload_to_kaggle()\n",
    "else:\n",
    "    print(\"Download failed, please try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-anti-spoofing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
